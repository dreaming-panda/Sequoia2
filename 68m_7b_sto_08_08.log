[2024-02-01 13:42:44,966] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Namespace(model='JackFram/llama-68m', target='meta-llama/Llama-2-7b-hf', dataset='dataset/c4_small.json', start=0, end=200, T=0.8, P=0.8, DP=0.99, ALG='coverplus', D=1, B=10, W=32, M=288, Mode='greedy', decay=0.85, negative=False, static=False, offloading=False)
1.5
1.9701492537313432
1.934782608695652
1.9306930693069306
1.9341317365269461
1.9356223175965666
1.9463087248322148
1.9344262295081966
1.9344262295081966
1.9262672811059909
1.9175050301810865
1.9200710479573713
1.9200710479573713
1.9206349206349207
1.9183381088825215
1.9151436031331592
1.9216867469879517
1.9208472686733555
1.9222689075630253
1.921765295887663
1.9238005644402634
1.9238005644402634
1.9281277728482697
1.9312080536912752
1.9301032565528198
1.9305660377358491
1.9275466284074605
1.9307270233196159
1.9311023622047243
1.9301423027166882
1.9323401613904407
1.9337708830548925
1.9337708830548925
1.9334480780263912
1.9320817228050802
1.9315673289183224
1.9315673289183224
1.9292929292929293
1.9300518134715026
1.9313283208020051
1.9315866084425037
1.9295774647887325
1.9272396543883583
1.9264440433212997
1.927256792287467
1.927256792287467
1.9267773520647085
1.9287194363862412
1.9301856335754641
1.9300589390962672
1.9310344827586208
1.9312406576980568
1.9314369073668856
1.9307720188474085
1.9302901627742393
1.9302901627742393
1.9288428324697755
1.9303818857722204
1.9302709847984139
1.9298415777562237
1.9306523115896137
1.9320297951582868
1.932765439610587
1.93289591410677
1.9330213512723018
1.9330213512723018
1.9336969001148105
1.9339031339031338
1.9345454545454546
1.9343767160900605
1.9329021827000807
1.9319925906324424
1.9313750974785546
1.9322597137014315
1.932527693856999
1.932639920752848
1.932992202729045
1.9328698153919923
1.9328571428571428
1.9320524835988753
1.931685707624155
1.9307021569527305
1.9312683698846937
1.9312683698846937
1.9307503896682254
1.9304519526107942
1.9304519526107942
1.9303783783783783
1.9303783783783783
1.9294844482317852
1.9288114237715246
1.9293557074787653
1.9293011851246424
1.930026214962694
1.9297652208515719
1.9295468038788839
1.928711704634721
1.9286683465787944
1.9291730474732005
1.9293005671077506
1.9297852474323063
1.929462125442025
1.929190484971418
1.9294953543450537
1.9278776978417267
1.927847876310645
1.9269662921348314
1.926774249522818
1.926774249522818
1.9265866209262437
1.9265728336442258
1.9273611810098976
1.9274368834643036
1.9270521768029245
1.9273504273504274
1.9270156046814044
1.9273078160180122
1.9273078160180122
1.9268215081132676
1.9274130058258543
1.9273917108133374
1.9274256346363494
1.9273968352466646
1.92767199017199
1.9276485788113695
1.92675590314333
1.9264552627661158
1.9264445754716981
1.926434097212086
1.926434097212086
1.926145396733632
1.9265463917525774
1.926808510638298
1.9274669665448412
1.9274474307199554
1.9266308095435112
1.926882602159355
1.9269418794133624
1.9269277351635041
1.9270374816593303
1.9264355649642764
1.9262338347849037
1.9257225055577352
1.9262188796680497
1.9264592440215993
1.9266955634880163
1.9264408493427705
1.9267895198696252
1.9267895198696252
1.9267015706806283
1.926805143422354
1.926805143422354
1.9267933782955242
1.9254892427373282
1.9252561784207354
1.9251375269074384
1.925020761656187
1.9251324308416715
1.9251324308416715
1.9252423782268426
1.9250202804496466
1.9251040221914009
1.9251060901479526
1.9251202198305473
1.9255597226957608
1.9254455222197158
1.9252294604880233
1.9251670378619155
1.9252708379394208
1.9254828797190517
1.9255829156679014
1.9254901960784314
1.925489347896615
1.9257946735395188
1.9257234726688104
1.9256771166560034
1.9256771166560034
1.9259769141162766
1.9264752287787945
1.9265642954141857
1.9266521423384169
1.9268570246223877
1.92649184389841
1.9263816261663078
1.9263816261663078
1.9258806760333944
1.9260720064724919
1.926067302862883
1.9259628816603471
1.9261498810467883
1.9258566364710517
1.9258566364710517
1.9260418704754452
1.9261275272161742
1.9261275272161742
1.926087801087801
1.9258008490930143
1.9261674177773516
1.9258835857864152
1.925785687239682
total decoding steps: 20344 large model steps: 10564 avg decoding step: 1.925785687239682
tensor([0.5818, 0.1134, 0.0526, 0.0313, 0.0228, 0.0176, 0.0126, 0.0118, 0.0100,
        0.0078, 0.0061, 0.0061, 0.0047, 0.0044, 0.0034, 0.0044, 0.0033, 0.0043,
        0.0028, 0.0026, 0.0034, 0.0022, 0.0018, 0.0019, 0.0020, 0.0012, 0.0018,
        0.0016, 0.0016, 0.0016, 0.0012, 0.0016, 0.0742], device='cuda:0')
tensor([0.5818, 0.6952, 0.7478, 0.7792, 0.8020, 0.8196, 0.8322, 0.8440, 0.8540,
        0.8618, 0.8679, 0.8739, 0.8786, 0.8831, 0.8865, 0.8909, 0.8942, 0.8984,
        0.9013, 0.9038, 0.9072, 0.9094, 0.9112, 0.9131, 0.9151, 0.9163, 0.9181,
        0.9197, 0.9213, 0.9229, 0.9242, 0.9258, 1.0000], device='cuda:0')
