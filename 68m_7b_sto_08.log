[2024-02-01 13:35:28,429] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Namespace(model='JackFram/llama-68m', target='meta-llama/Llama-2-7b-hf', dataset='dataset/c4_small.json', start=0, end=200, T=0.8, P=1.0, DP=0.99, ALG='coverplus', D=1, B=10, W=32, M=288, Mode='greedy', decay=0.85, negative=False, static=False, offloading=False)
1.8823529411764706
1.9310344827586208
1.925
1.911764705882353
1.9194915254237288
1.9271523178807948
1.9320652173913044
1.9310344827586208
1.9310344827586208
1.9282868525896415
1.9295774647887325
1.9296740994854202
1.9296740994854202
1.9203675344563553
1.9221140472879
1.9248407643312102
1.921453692848769
1.9185667752442996
1.9184100418410042
1.9197651663405089
1.914835164835165
1.914835164835165
1.9187554019014694
1.9183333333333332
1.9126671911880408
1.913303437967115
1.9131672597864768
1.9140845070422534
1.9113498992612492
1.912540192926045
1.9142504626773598
1.9169632265717675
1.9169632265717675
1.917284654877353
1.917032967032967
1.916529379461834
1.916529379461834
1.917329093799682
1.9176049129989765
1.919266963843487
1.919904076738609
1.9209669920966992
1.9189189189189189
1.9199475065616798
1.9184713375796179
1.9184713375796179
1.9166666666666667
1.9188102893890675
1.918982387475538
1.9158415841584158
1.915707389528407
1.916636462486408
1.9171681415929203
1.916637230660544
1.9161779924111764
1.9161779924111764
1.9141124957898281
1.9152933421226104
1.9149771092217136
1.9158130601792573
1.9169018501097523
1.917357910906298
1.9172033118675254
1.9179440937781786
1.9183613321544355
1.9183613321544355
1.9198727220133063
1.9210675752413402
1.9204961939667324
1.9208414060337669
1.9204020646563433
1.9210034694422204
1.9205766710353867
1.9218870843000773
1.9218508997429307
1.9214249621020718
1.9214906832298138
1.9222493887530563
1.922762271414822
1.9230222643297015
1.9235074626865671
1.9232011070110702
1.9227974568574024
1.9227974568574024
1.9229374433363553
1.9229738780977896
1.9229738780977896
1.9227892652881655
1.9227892652881655
1.9228267938434858
1.9218282785134557
1.9213554987212276
1.9218158890290038
1.9226622434169605
1.9224948875255623
1.9222379317309635
1.9205495818399043
1.9209905660377358
1.9209803921568627
1.920843816527966
1.9214449541284404
1.9207696661007356
1.9211850195640023
1.9212366580787634
1.919542317471849
1.9197774587221823
1.9179659815733523
1.9182136602451838
1.9182136602451838
1.917392819797839
1.917815299793246
1.9181864666780297
1.9179443976411121
1.9185
1.9184110763144882
1.9180114099429504
1.917819365337673
1.917819365337673
1.9180486234100789
1.918017006257019
1.917288458485474
1.9176507636592663
1.9171339563862928
1.9170815183571872
1.9156923076923076
1.9157910765950967
1.9157371118480555
1.9156644618159953
1.915327380952381
1.915327380952381
1.915511648481274
1.9158878504672898
1.9155581260844419
1.9156591824985607
1.9161557108227578
1.916049030786773
1.9161372299872934
1.9162692847124825
1.9165391570454862
1.9167470709855272
1.9172131147540983
1.9170299727520437
1.9165879335942773
1.9166666666666667
1.916766706682673
1.9169641676583367
1.9171582120854633
1.917099792099792
1.917099792099792
1.9165486155827431
1.9161347970385498
1.9161347970385498
1.9162131375775218
1.9161646586345382
1.916240169766571
1.9164293673393586
1.9160324085440708
1.9163419386264005
1.9163419386264005
1.916525730852863
1.9169363538295576
1.9160822536550577
1.9162637103432008
1.9162735849056605
1.9164521413526796
1.9162990480612956
1.9163690819030066
1.9163883450420363
1.9163428571428571
1.9166288566243195
1.9166948103118315
1.9162186379928314
1.9161756531406338
1.9164551374020526
1.9163909110964041
1.9161375082110794
1.9161375082110794
1.9165126644200456
1.9165767321390028
1.9166666666666667
1.9166222411770977
1.916613689340962
1.9166754339821146
1.9168320969595654
1.9168320969595654
1.9165888577653283
1.9168469860896444
1.916941128036229
1.9168029435813574
1.9170558375634519
1.9166246597439258
1.9166246597439258
1.9158158158158158
1.9157633018398808
1.9157633018398808
1.9158386327503976
1.9162799881528285
1.916429622363904
1.9163905671409083
1.916512780639518
total decoding steps: 19719 large model steps: 10289 avg decoding step: 1.916512780639518
tensor([0.5841, 0.0979, 0.0539, 0.0310, 0.0222, 0.0190, 0.0123, 0.0103, 0.0102,
        0.0080, 0.0072, 0.0067, 0.0052, 0.0044, 0.0054, 0.0048, 0.0032, 0.0030,
        0.0027, 0.0025, 0.0018, 0.0010, 0.0020, 0.0019, 0.0021, 0.0022, 0.0023,
        0.0018, 0.0018, 0.0016, 0.0018, 0.0019, 0.0835], device='cuda:0')
tensor([0.5841, 0.6820, 0.7359, 0.7669, 0.7891, 0.8080, 0.8204, 0.8307, 0.8409,
        0.8489, 0.8561, 0.8628, 0.8679, 0.8723, 0.8777, 0.8825, 0.8857, 0.8887,
        0.8914, 0.8940, 0.8958, 0.8968, 0.8988, 0.9008, 0.9029, 0.9051, 0.9075,
        0.9093, 0.9112, 0.9127, 0.9146, 0.9165, 1.0000], device='cuda:0')
